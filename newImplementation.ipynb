{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 3107\n",
      "Number of columns: 9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming the dataset is in CSV format. Replace 'path_to_dataset.csv' with the actual file path\n",
    "df = pd.read_csv('drugLibTrain_raw.tsv', delimiter='\\t')\n",
    "print(f\"Number of rows: {df.shape[0]}\")\n",
    "print(f\"Number of columns: {df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "df = df.dropna()\n",
    "# Create TF-IDF vectors for each free-text column\n",
    "# tfidf_benefits = tfidf_vectorizer.fit_transform(df['benefitsReview'])\n",
    "# tfidf_sideEffects = tfidf_vectorizer.fit_transform(df['sideEffectsReview'])\n",
    "# tfidf_comments = tfidf_vectorizer.fit_transform(df['commentsReview'])\n",
    "\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "tfidf_benefits = count_vectorizer.fit_transform(df['benefitsReview'])\n",
    "tfidf_sideEffects = count_vectorizer.fit_transform(df['sideEffectsReview'])\n",
    "tfidf_comments = count_vectorizer.fit_transform(df['commentsReview'])\n",
    "\n",
    "\n",
    "# hashing_vectorizer = HashingVectorizer()\n",
    "\n",
    "# tfidf_benefits = hashing_vectorizer.fit_transform(df['benefitsReview'])\n",
    "# tfidf_sideEffects = hashing_vectorizer.fit_transform(df['sideEffectsReview'])\n",
    "# tfidf_comments = hashing_vectorizer.fit_transform(df['commentsReview'])\n",
    "\n",
    "\n",
    "\n",
    "# # Tokenize the text data\n",
    "# tfidf_benefits = df['benefitsReview'].apply(lambda x: x.split())\n",
    "# tfidf_sideEffects = df['sideEffectsReview'].apply(lambda x: x.split())\n",
    "# tfidf_comments = df['commentsReview'].apply(lambda x: x.split())\n",
    "\n",
    "# # Train Word2Vec models\n",
    "# tfidf_benefits = Word2Vec(tfidf_benefits, min_count=1)\n",
    "# tfidf_sideEffects = Word2Vec(tfidf_sideEffects, min_count=1)\n",
    "# tfidf_comments = Word2Vec(tfidf_comments, min_count=1)\n",
    "\n",
    "# # Convert the text data into word embeddings\n",
    "# tfidf_benefits = tfidf_benefits.wv[tfidf_benefits]\n",
    "# tfidf_sideEffects = tfidf_sideEffects.wv[tfidf_sideEffects]\n",
    "# tfidf_comments = tfidf_comments.wv[tfidf_comments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Combine the TF-IDF vectors into one matrix\n",
    "tfidf_combined = hstack([tfidf_benefits, tfidf_sideEffects, tfidf_comments])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Features\n",
    "X = tfidf_combined\n",
    "\n",
    "# Labels\n",
    "y_rating = df['rating']\n",
    "y_effectiveness = df['effectiveness']\n",
    "y_sideEffects = df['sideEffects']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_rating, y_test_rating = train_test_split(X, y_rating, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_effectiveness, y_test_effectiveness = train_test_split(X, y_effectiveness, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_sideEffects, y_test_sideEffects = train_test_split(X, y_sideEffects, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating MSE: 5.921549169435217\n",
      "Effectiveness Accuracy: 0.45016611295681064\n",
      "SideEffect Accuracy: 0.5365448504983389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Assuming 'tfidf_combined' is your combined TF-IDF matrix and\n",
    "# 'df['rating']', 'df['effectiveness']', 'df['sideEffects']' are your labels\n",
    "\n",
    "# Split the data for rating prediction\n",
    "X_train_rating, X_test_rating, y_train_rating, y_test_rating = train_test_split(\n",
    "    tfidf_combined, df['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data for effectiveness prediction\n",
    "X_train_effectiveness, X_test_effectiveness, y_train_effectiveness, y_test_effectiveness = train_test_split(\n",
    "    tfidf_combined, df['effectiveness'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data for sideEffect prediction\n",
    "X_train_sideEffect, X_test_sideEffect, y_train_sideEffect, y_test_sideEffect = train_test_split(\n",
    "    tfidf_combined, df['sideEffects'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "rating_model = RandomForestRegressor()\n",
    "effectiveness_model = RandomForestClassifier()\n",
    "sideEffect_model = RandomForestClassifier()\n",
    "\n",
    "# Train models\n",
    "rating_model.fit(X_train_rating, y_train_rating)\n",
    "effectiveness_model.fit(X_train_effectiveness, y_train_effectiveness)\n",
    "sideEffect_model.fit(X_train_sideEffect, y_train_sideEffect)\n",
    "\n",
    "# Predict\n",
    "rating_predictions = rating_model.predict(X_test_rating)\n",
    "effectiveness_predictions = effectiveness_model.predict(X_test_effectiveness)\n",
    "sideEffect_predictions = sideEffect_model.predict(X_test_sideEffect)\n",
    "\n",
    "# Evaluate\n",
    "rating_mse = mean_squared_error(y_test_rating, rating_predictions)\n",
    "effectiveness_accuracy = accuracy_score(y_test_effectiveness, effectiveness_predictions)\n",
    "sideEffect_accuracy = accuracy_score(y_test_sideEffect, sideEffect_predictions)\n",
    "\n",
    "# Print out the performance\n",
    "print(f'Rating MSE: {rating_mse}')\n",
    "print(f'Effectiveness Accuracy: {effectiveness_accuracy}')\n",
    "print(f'SideEffect Accuracy: {sideEffect_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating MSE: 6.924594518272425\n",
      "Effectiveness Accuracy: 0.4418604651162791\n",
      "SideEffect Accuracy: 0.45514950166112955\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "# df = pd.read_csv('path_to_your_dataset.csv')\n",
    "df = pd.read_csv('drugLibTrain_raw.tsv', delimiter='\\t')\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert categorical labels to numerical\n",
    "le = LabelEncoder()\n",
    "df['effectiveness'] = le.fit_transform(df['effectiveness'])\n",
    "df['sideEffects'] = le.fit_transform(df['sideEffects'])\n",
    "\n",
    "# Generate TF-IDF vectors\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# tfidf_combined = tfidf_vectorizer.fit_transform(df['benefitsReview'] + ' ' + df['sideEffectsReview'] + ' ' + df['commentsReview'])\n",
    "\n",
    "# count_vectorizer = CountVectorizer()\n",
    "# tfidf_combined = count_vectorizer.fit_transform(df['benefitsReview'] + ' ' + df['sideEffectsReview'] + ' ' + df['commentsReview'])\n",
    "\n",
    "hashing_vectorizer = HashingVectorizer()\n",
    "tfidf_combined = hashing_vectorizer.fit_transform(df['benefitsReview'] + ' ' + df['sideEffectsReview'] + ' ' + df['commentsReview'])\n",
    "\n",
    "\n",
    "# combined_text = (df['benefitsReview'] + ' ' + df['sideEffectsReview'] + ' ' + df['commentsReview']).apply(lambda x: x.split())\n",
    "# w2v_model = Word2Vec(combined_text, min_count=1)\n",
    "# tfidf_combined = combined_text.apply(lambda x: [w2v_model.wv[word] for word in x])\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train_rating, y_test_rating = train_test_split(tfidf_combined, df['rating'], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_effectiveness, y_test_effectiveness = train_test_split(tfidf_combined, df['effectiveness'], test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_sideEffect, y_test_sideEffect = train_test_split(tfidf_combined, df['sideEffects'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "rating_model = RandomForestRegressor(n_estimators=100, max_depth=None, random_state=0)\n",
    "effectiveness_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "sideEffect_model = RandomForestClassifier(n_estimators=100, max_depth=None, random_state=0)\n",
    "\n",
    "# Train models\n",
    "rating_model.fit(X_train, y_train_rating)\n",
    "effectiveness_model.fit(X_train, y_train_effectiveness)\n",
    "sideEffect_model.fit(X_train, y_train_sideEffect)\n",
    "\n",
    "# Predict\n",
    "rating_predictions = rating_model.predict(X_test)\n",
    "effectiveness_predictions = effectiveness_model.predict(X_test)\n",
    "sideEffect_predictions = sideEffect_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rating_mse = mean_squared_error(y_test_rating, rating_predictions)\n",
    "effectiveness_accuracy = accuracy_score(y_test_effectiveness, effectiveness_predictions)\n",
    "sideEffect_accuracy = accuracy_score(y_test_sideEffect, sideEffect_predictions)\n",
    "\n",
    "# Print out the performance.00\n",
    "print(f'Rating MSE: {rating_mse}')\n",
    "print(f'Effectiveness Accuracy: {effectiveness_accuracy}')\n",
    "print(f'SideEffect Accuracy: {sideEffect_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3023255813953488\n",
      "Precision: 0.2614199426699427\n",
      "Recall: 0.3023255813953488\n",
      "F1 Score: 0.21762052384882627\n",
      "Confusion Matrix: \n",
      "[[ 17   0   0   0   0   0   0   8   0  27]\n",
      " [  5   0   0   0   0   0   0   5   0  11]\n",
      " [  3   0   0   0   0   0   0  16   2  11]\n",
      " [  2   0   0   0   0   0   0   9   0  12]\n",
      " [  3   0   0   0   0   0   0  13   2  14]\n",
      " [  1   0   0   0   0   1   1  18   1  18]\n",
      " [  2   0   0   0   0   0   0  26   4  26]\n",
      " [  1   0   0   0   0   0   0  41   7  68]\n",
      " [  3   0   0   0   0   0   0  24   6  48]\n",
      " [  2   0   0   0   0   0   0  25   2 117]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vickyprince/opt/anaconda3/envs/myFirstEnv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Combine all the TF-IDF dataframes\n",
    "# df_tfidf = pd.concat([df_tfidf_benefits, df_tfidf_sideEffects, df_tfidf_comments], axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_combined, df['rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf = MultinomialNB()\n",
    "clf = SVC()\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the ratings\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate metrics for rating prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45348837209302323\n",
      "Precision: 0.4443502685981276\n",
      "Recall: 0.45348837209302323\n",
      "F1 Score: 0.35305486956488386\n",
      "Confusion Matrix: \n",
      "[[ 38 151   0   0   0]\n",
      " [ 26 233   0   0   0]\n",
      " [  2  41   1   0   0]\n",
      " [  7  22   0   1   0]\n",
      " [ 25  55   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vickyprince/opt/anaconda3/envs/myFirstEnv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Combine all the TF-IDF dataframes\n",
    "# df_tfidf = pd.concat([df_tfidf_benefits, df_tfidf_sideEffects, df_tfidf_comments], axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_combined, df['effectiveness'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf = MultinomialNB()\n",
    "clf = SVC()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the ratings\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate metrics for rating prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5083056478405316\n",
      "Precision: 0.5314108629572397\n",
      "Recall: 0.5083056478405316\n",
      "F1 Score: 0.43132112140242873\n",
      "Confusion Matrix: \n",
      "[[  0  20   3  10   0]\n",
      " [  0 182   5  22   0]\n",
      " [  0  98  10  10   0]\n",
      " [  0  54   3 109   0]\n",
      " [  0  50  10  11   5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vickyprince/opt/anaconda3/envs/myFirstEnv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Combine all the TF-IDF dataframes\n",
    "# df_tfidf = pd.concat([df_tfidf_benefits, df_tfidf_sideEffects, df_tfidf_comments], axis=1)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_combined, df['sideEffects'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# clf = MultinomialNB()\n",
    "clf = SVC()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the ratings\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "# Calculate metrics for rating prediction\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Confusion Matrix: \\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myFirstEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
